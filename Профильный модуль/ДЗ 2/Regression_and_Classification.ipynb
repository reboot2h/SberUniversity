{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r_lVVaJl2Ncb"
      },
      "source": [
        "# Регрессия"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3pECYqXD2VjG"
      },
      "source": [
        "С 1ого октября отменяется НДС на бриллианты, теперь они становятся новым инвестиционным инструментом. Давайте сделаем модель ценообразования для них.\n",
        "\n",
        "Скачайте датасет diamonds.csv\n",
        "\n",
        "В нем представлены характеристики бриллиантов и их цены с сайта jamesallen (B2C площадка) с 2022-07-01\n",
        "\n",
        "**Описание полей**\n",
        "\n",
        "\n",
        "* fluor - флуорисценуия (свойство камня светиться в лучах ультр)\n",
        "* symmetry - показатель симметричности\n",
        "* platform - название платформы, где был размещен камень\n",
        "* quality_group - составной показатель из cut polish symmetry\n",
        "* size_group - каратно весовая группа\n",
        "* big_size_group - каратно-весовая группа\n",
        "* shape - форма\n",
        "* color - цвет\n",
        "* clarity - чистота\n",
        "* cut - качество огранки (может быть только у круглых камней)\n",
        "* polish - полировка\n",
        "* id - номер камня\n",
        "* date - дата\n",
        "* price - цена\n",
        "* carat - кол-во карат\n",
        "* tablepercent - размер площадки по отношению ширине\n",
        "* price_per_carat - цена за карат\n",
        "* z - длина (diameter)\n",
        "* x - ширина\n",
        "* depth_perc - отношение высоты к ширине\n",
        "* y - высота\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "iOnp-6t565z8"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C4f2-y_7bfv8",
        "outputId": "5792d6b6-7adb-4865-e028-eebb47d7d609"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')\n",
        "\n",
        "# path = 'drive/MyDrive/'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "iG7MP6VZ2UZN"
      },
      "outputs": [],
      "source": [
        "# df = pd.read_csv(path + 'diamonds.csv', index_col=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "df = pd.read_csv('diamonds.csv', index_col=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PD8Sv2_ktIqx"
      },
      "source": [
        "Хоти предсказать price_per_carat"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HEBGHQkD7DWw"
      },
      "source": [
        "## Задание 1: Очистка\n",
        "\n",
        "Не все камни успевают продаться за один месяц, поэтому в таблице есть повторы. Объедините данные по одному камню: подумайте, как лучше это сделать, какую цену брать.\n",
        "\n",
        "Попробуйте найти аномалии: вдруг цена на некоторые камни сильно меняется (то есть продавец сам не знает, по какой цене их продавать). Также убедитесь, что остальные параметры камня не меняются."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 232,
      "metadata": {
        "id": "uL1lalBa7AVS"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\ogloc\\AppData\\Local\\Temp\\ipykernel_22060\\403455913.py:10: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
            "  stat = df_three.groupby('id')['price', 'carat', 'price_per_carat', 'z', 'x', 'depth_perc', 'y'].agg(np.std) # Посчитайте дстандартное отклонение по по нескольким полям,\n"
          ]
        }
      ],
      "source": [
        "id_stat = df.groupby(by='id')['carat'].count().to_frame() #Посчитайте статистику по кол-ву камней\n",
        "\n",
        "# разделите выборку на две части\n",
        "id_count_1 = id_stat[id_stat['carat'] == 1]\n",
        "df_one = df.query('id in @id_count_1.index')  # те камни, которые встречались один раз\n",
        "id_count_2_3 = id_stat[(id_stat['carat'] == 2) + (id_stat['carat'] == 3)]\n",
        "df_three = df.query('id in @id_count_2_3.index') # те камни, которые встречались 2 или 3 раза\n",
        "\n",
        "\n",
        "stat = df_three.groupby('id')['price', 'carat', 'price_per_carat', 'z', 'x', 'depth_perc', 'y'].agg(np.std) # Посчитайте дстандартное отклонение по по нескольким полям,\n",
        "#  подумайте где оно должно равняться 0, а где меняться в каких-то разумных пределах\n",
        "anomaly_ids = list(stat[(stat['carat'] > 0) + (stat['z'] > 0) + (stat['x'] > 0) + (stat['depth_perc'] > 0) + (stat['y'] > 0)].index)\n",
        "iqr = stat['price_per_carat'].quantile(0.75) - stat['price_per_carat'].quantile(0.25)\n",
        "stat[stat['price_per_carat'] > 1.5 * stat['price_per_carat'].quantile(0.75)].index\n",
        "anomaly_ids.append(stat[stat['price_per_carat'] > 1.5 * stat['price_per_carat'].quantile(0.75)].index)\n",
        "\n",
        "# Удалите аномальные наблюдения\n",
        "df_three = df_three.query('id not in @anomaly_ids').sort_values(by=['id','date'])\n",
        "\n",
        "df_three = df_three.groupby('id').agg('last').reset_index() #тепреь в качестве цены возьмем последнее значение по времени\n",
        "\n",
        "df = pd.concat([df_one, df_three]).reset_index(drop=True) # соединяем результаты"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NnsNVat_CIPB"
      },
      "source": [
        "Цены на бриллианты достаточно сильно меняются, попробуйте вычислить коэффициент инфляции и привести цены к последнему месяцу. Стоит учесть, что цены на все бриллианты не изменяются синхронно, то есть изменение в определенных группах может быть разным.\n",
        "\n",
        "Определите эти группы и рассчитайте коэффициенты инфляции для каждой из них. Подправьте цены на эти коэффициенты и создайте новую переменную."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nDKdDba4pA7M"
      },
      "outputs": [],
      "source": [
        "categories = ['...'] #определите по каким группам отпределять инфляцию (к примеру можно добавить каратную группу)\n",
        "\n",
        "df_index = df.groupby(['date'] + categories)[['price_per_carat']]\\\n",
        "                                                                .mean()\\\n",
        "                                                                    .reset_index() # индекс цен\n",
        "\n",
        "date_max = df_index.date.max()\n",
        "\n",
        "\n",
        "df_index = df_index.merge(df_index.query('date == @date_max')[categories + ['price_per_carat']]\\\n",
        "                          .rename(columns={'price_per_carat': 'price_per_carat_max'}), \n",
        "                          on=categories, how='outer') # сопоставляем группы с максимальной датой\n",
        "\n",
        "df_index['inflation'] = df_index.['...'] / df_index.price_per_carat # вычисляем инфляцию\n",
        "\n",
        "df_with_inf = df.merge(df_index[['date'] + categories + ['inflation']], \n",
        "                        on=['date'] + categories, how='left') # соединяем все в одной таблице"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xuPhXT9aESGs"
      },
      "source": [
        "## Задание 2: Модель"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v3OgAHMiExrW"
      },
      "source": [
        "Определите функцию потерь (MSE или MAE) и аргументируйте выбор.\n",
        "Попробуйте сделать baseline.\n",
        "Используйте LableEncoder для категориальных фичей и постройте линейную модель."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BEvWYr1uEKJU"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LableEncoder\n",
        "from sklearn.metrics import ...\n",
        "\n",
        "\n",
        "X = df.drop(columns=[\"...\"])\n",
        "y = df[\"...\"]\n",
        "\n",
        "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2, random_state=13)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z9kiKhHuFDUD"
      },
      "source": [
        "Теперь попробуйте OHE или TargetEncoder (сравните их).\n",
        "\n",
        "Нормализуйте данные.\n",
        "\n",
        "Поработайте с пропусками (обратите внимание на то, что у fluor возможен пропуск значения, а возможно отсутствие флуоресценции)\n",
        "\n",
        "Покажите, насколько получилось улучшить результат."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 124,
      "metadata": {
        "id": "LeLrnXuepjjb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting category_encoders\n",
            "  Downloading category_encoders-2.5.1.post0-py2.py3-none-any.whl (72 kB)\n",
            "     ---------------------------------------- 72.4/72.4 kB 2.0 MB/s eta 0:00:00\n",
            "Requirement already satisfied: scikit-learn>=0.20.0 in c:\\users\\ogloc\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from category_encoders) (1.1.2)\n",
            "Collecting patsy>=0.5.1\n",
            "  Downloading patsy-0.5.3-py2.py3-none-any.whl (233 kB)\n",
            "     -------------------------------------- 233.8/233.8 kB 4.8 MB/s eta 0:00:00\n",
            "Requirement already satisfied: pandas>=1.0.5 in c:\\users\\ogloc\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from category_encoders) (1.5.1)\n",
            "Collecting statsmodels>=0.9.0\n",
            "  Downloading statsmodels-0.13.5-cp310-cp310-win_amd64.whl (9.1 MB)\n",
            "     ---------------------------------------- 9.1/9.1 MB 10.4 MB/s eta 0:00:00\n",
            "Requirement already satisfied: numpy>=1.14.0 in c:\\users\\ogloc\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from category_encoders) (1.23.4)\n",
            "Requirement already satisfied: scipy>=1.0.0 in c:\\users\\ogloc\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from category_encoders) (1.9.3)\n",
            "Requirement already satisfied: pytz>=2020.1 in c:\\users\\ogloc\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pandas>=1.0.5->category_encoders) (2022.5)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\ogloc\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pandas>=1.0.5->category_encoders) (2.8.2)\n",
            "Requirement already satisfied: six in c:\\users\\ogloc\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from patsy>=0.5.1->category_encoders) (1.16.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\ogloc\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from scikit-learn>=0.20.0->category_encoders) (3.1.0)\n",
            "Requirement already satisfied: joblib>=1.0.0 in c:\\users\\ogloc\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from scikit-learn>=0.20.0->category_encoders) (1.2.0)\n",
            "Requirement already satisfied: packaging>=21.3 in c:\\users\\ogloc\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from statsmodels>=0.9.0->category_encoders) (21.3)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\ogloc\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from packaging>=21.3->statsmodels>=0.9.0->category_encoders) (3.0.9)\n",
            "Installing collected packages: patsy, statsmodels, category_encoders\n",
            "Successfully installed category_encoders-2.5.1.post0 patsy-0.5.3 statsmodels-0.13.5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip available: 22.3 -> 22.3.1\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        }
      ],
      "source": [
        "!pip install category_encoders"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "becHgg71Iria"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from category_encoders import TargetEncoder\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "from typing import Tuple, List\n",
        "\n",
        "\n",
        "def OHE(df: pd.DataFrame, columns: List[str]) -> Tuple[pd.DataFrame, List[str]]:\n",
        "    index = df.index\n",
        "    one = OneHotEncoder(sparse=False, categories='auto')\n",
        "    ohe = one.fit_transform(df[columns])\n",
        "    col_names = one.get_feature_names(input_features = columns)\n",
        "    df = df.drop(columns, axis=1)\n",
        "    df = df.reset_index(drop=True)\n",
        "    df = pd.concat([df, pd.DataFrame(ohe, columns=col_names)], axis = 1)\n",
        "    df = df.set_index(index)\n",
        "    return (df, col_names)\n",
        "\n",
        "scaler = StandardScaler() # Помните, что на тесте делаем только transform\n",
        "  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tnJUqYqWoqgk"
      },
      "source": [
        "Сравните с KNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bhKgkdw5ou4A"
      },
      "outputs": [],
      "source": [
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fLAsZpEeIsyk"
      },
      "source": [
        "# Классификация"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "exzgWs8TGVwz"
      },
      "source": [
        "Загрузите датасет bodyPerformance\n",
        "\n",
        "Описание:\n",
        "\n",
        "https://www.kaggle.com/datasets/kukuroo3/body-performance-data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HiRlpeObIw30",
        "outputId": "56c8bb8e-4fbc-471f-9ca4-e8ed0978abd6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "path = 'drive/MyDrive/'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8icMo8BR8eJL"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv(path + '/Classroom/DS 11 VI/ДЗ-регрессия_классификация/bodyPerformance.csv') #укажите свой путь"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mIT8KyvrGFI7"
      },
      "source": [
        "## Задание 1: Определение гендера"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P7hR4HE2GOjH"
      },
      "source": [
        "Постройте модель, которая будет определять гендер."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aAQJ1WhfGhQf"
      },
      "source": [
        "Для этого определите две метрики качества, на которые вы будете смотреть. Аргументируйте свой выбор.\n",
        "\n",
        "После чего преобразуйте категориальные переменные и постройте модель бинарной классификации на основе линейного классификатора и сравните с KNN.\n",
        "\n",
        "P.S.: не забудте про нормализацию."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mhj3I_MuBbFy"
      },
      "outputs": [],
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn import metrics\n",
        "\n",
        "X = df.drop(columns=[\"...\"])\n",
        "y = df[\"...\"]\n",
        "\n",
        "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2, random_state=13)\n",
        "\n",
        "scaler = StandardScaler()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9m0SK6JzKHof"
      },
      "source": [
        "## Задание 2: Определение класса"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s5Hge2C2JSxG"
      },
      "source": [
        "Теперь опробуем построить модель, которая будет предсказывать class физической формы.\n",
        "\n",
        "Для этого определите метрики качества для задачи мультиклассификации (аргументируйте выбор).\n",
        "\n",
        "Постройте модель мультиклассовой классификации на основе линейного классификатора и сравните с KNN."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dgvhCM7HKDWu"
      },
      "outputs": [],
      "source": [
        "X = df.drop(columns=[\"...\"]) # укажите новый таргет\n",
        "y = df[\"...\"]\n",
        "\n",
        "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2, random_state=13)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.10.5 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.5"
    },
    "vscode": {
      "interpreter": {
        "hash": "c814f020ca40bd9580eb35142fd8f4f123522e545ffe0e2f57f22b8f89ccd43d"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
